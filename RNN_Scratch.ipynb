{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "647400ec-01e5-41aa-9a6d-e75148830b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# dimensions\n",
    "input_size = 1\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "# weights\n",
    "Wxh = np.random.randn(hidden_size, input_size) * 0.01\n",
    "Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "Why = np.random.randn(output_size, hidden_size) * 0.01\n",
    "\n",
    "# biases\n",
    "bh = np.zeros((hidden_size, 1))\n",
    "by = np.zeros((output_size, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c4e957-58cd-464f-8ff6-166edf03b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input sequence\n",
    "X = [np.array([[1]]), np.array([[2]]), np.array([[3]])]\n",
    "Y = [np.array([[2]]), np.array([[4]]), np.array([[6]])]  # target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef03016f-f1eb-4526-8f65-abad8b29a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_prev = np.zeros((hidden_size, 1))\n",
    "hs = {}\n",
    "ys = {}\n",
    "\n",
    "for t in range(len(X)):\n",
    "    hs[t] = np.tanh(Wxh @ X[t] + Whh @ h_prev + bh)\n",
    "    ys[t] = Why @ hs[t] + by\n",
    "    h_prev = hs[t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd26d61-49b9-4f95-88ae-46a295f2f183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 56.01962908037016\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "for t in range(len(Y)):\n",
    "    loss += np.square(ys[t] - Y[t])\n",
    "\n",
    "print(\"Loss:\", loss[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc54b06f-e345-4b9f-8278-cdb086fd43c7",
   "metadata": {},
   "source": [
    "# Back Propagation through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c02c69-0bc9-4ec7-9acd-840220a453c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dWxh = np.zeros_like(Wxh)\n",
    "dWhh = np.zeros_like(Whh)\n",
    "dWhy = np.zeros_like(Why)\n",
    "dbh = np.zeros_like(bh)\n",
    "dby = np.zeros_like(by)\n",
    "\n",
    "dh_next = np.zeros_like(h_prev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf713d4a-cc3b-47af-9f97-421ccdd92217",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in reversed(range(len(X))):\n",
    "    dy = ys[t] - Y[t]\n",
    "    dWhy += dy @ hs[t].T\n",
    "    dby += dy\n",
    "\n",
    "    dh = Why.T @ dy + dh_next\n",
    "    dtanh = (1 - hs[t] ** 2) * dh\n",
    "\n",
    "    dbh += dtanh\n",
    "    dWxh += dtanh @ X[t].T\n",
    "    dWhh += dtanh @ hs[t-1].T if t > 0 else 0\n",
    "\n",
    "    dh_next = Whh.T @ dtanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f74c17-e093-4099-8ebf-c76ad08a42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wxh -= learning_rate * dWxh\n",
    "Whh -= learning_rate * dWhh\n",
    "Why -= learning_rate * dWhy\n",
    "bh  -= learning_rate * dbh\n",
    "by  -= learning_rate * dby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd9f64c6-0d62-44d3-84a5-4742b6db972b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 53.17024697852227\n",
      "Epoch 100, Loss: 1.1758970565815385\n",
      "Epoch 200, Loss: 0.03515377404884714\n",
      "Epoch 300, Loss: 0.005957144536961547\n",
      "Epoch 400, Loss: 0.0024095217195119053\n",
      "Epoch 500, Loss: 0.00099951940562552\n",
      "Epoch 600, Loss: 0.0004127753103659227\n",
      "Epoch 700, Loss: 0.00016994859019575496\n",
      "Epoch 800, Loss: 6.983990646036436e-05\n",
      "Epoch 900, Loss: 2.8666615553039435e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    # forward\n",
    "    h_prev = np.zeros((hidden_size, 1))\n",
    "    hs, ys = {}, {}\n",
    "    loss = 0\n",
    "\n",
    "    for t in range(len(X)):\n",
    "        hs[t] = np.tanh(Wxh @ X[t] + Whh @ h_prev + bh)\n",
    "        ys[t] = Why @ hs[t] + by\n",
    "        loss += np.square(ys[t] - Y[t])\n",
    "        h_prev = hs[t]\n",
    "\n",
    "    # backward\n",
    "    dWxh = np.zeros_like(Wxh)\n",
    "    dWhh = np.zeros_like(Whh)\n",
    "    dWhy = np.zeros_like(Why)\n",
    "    dbh = np.zeros_like(bh)\n",
    "    dby = np.zeros_like(by)\n",
    "    dh_next = np.zeros_like(h_prev)\n",
    "\n",
    "    for t in reversed(range(len(X))):\n",
    "        dy = ys[t] - Y[t]\n",
    "        dWhy += dy @ hs[t].T\n",
    "        dby += dy\n",
    "        dh = Why.T @ dy + dh_next\n",
    "        dtanh = (1 - hs[t] ** 2) * dh\n",
    "        dbh += dtanh\n",
    "        dWxh += dtanh @ X[t].T\n",
    "        dWhh += dtanh @ hs[t-1].T if t > 0 else 0\n",
    "        dh_next = Whh.T @ dtanh\n",
    "\n",
    "    # update\n",
    "    Wxh -= learning_rate * dWxh\n",
    "    Whh -= learning_rate * dWhh\n",
    "    Why -= learning_rate * dWhy\n",
    "    bh  -= learning_rate * dbh\n",
    "    by  -= learning_rate * dby\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6adde-3a51-46e1-b7bc-117dc5f2122e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
